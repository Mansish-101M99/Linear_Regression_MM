{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sb \n",
    "\n",
    "from sklearn.model_selection import train_test_split, validation_curve  \n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn import preprocessing \n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "import nbformat \n",
    "from IPython import get_ipython \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run \"../Data_Preprocessing/data_preprocess.ipynb\" \n",
    "\n",
    "with open(\"../Data_Preprocessing/data_preprocess_test.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
    "    notebook1 = nbformat.read(f, as_version=4)\n",
    "\n",
    "ipython = get_ipython() \n",
    "\n",
    "for cell in notebook1.cells:\n",
    "    if cell.cell_type == \"code\":\n",
    "        print(cell.source) \n",
    "        if (\"movies_test_data_cleaned\" in cell.source or \"movie_colen_data\" in cell.source):\n",
    "            ipython.run_cell(cell.source, silent=True) \n",
    "            # ipython.run_cell_async(cell.source, silent=True) \n",
    "\n",
    "try:\n",
    "    print(\"Movies Test Clean Data : \")\n",
    "    print(movies_test_data_cleaned.head(), sep='\\n')      # type: ignore \n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"Variable not found: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_test_data_cleaned      # type: ignore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_multi = movies_test_data_cleaned.drop('Collection', axis = 1)       # type: ignore \n",
    "X_multi  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_multi = movies_test_data_cleaned['Collection']       # type: ignore \n",
    "y_multi "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train - Test Split :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_multi, y_multi, test_size = 0.3, random_state = 0)    \n",
    "\n",
    "print(f\" X_train size : {X_train.shape} \\n X_test size : {X_test.shape} \\n y_train size : {y_train.shape} \\n y_test size : {y_test.shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalar formation for X values - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train) \n",
    "\n",
    "X_train_s = scaler.transform(X_train) \n",
    "X_test_s = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regression - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model_r = Ridge(alpha = 0.6)     # alpha ~ theoretical lambda value \n",
    "lin_model_r.fit(X_train_s, y_train) \n",
    "\n",
    "r2 = r2_score(y_test, lin_model_r.predict(X_test_s)) \n",
    "print(f\"r2 score = {r2}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_rg = np.logspace(-2, 8, 100)     # 100 values from 10^-2 to 10^8 \n",
    "param_rg   # Range of alphas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores, test_scores = validation_curve(Ridge(), X_train_s, y_train, param_name=\"alpha\", param_range=param_rg, scoring='r2')  \n",
    "# This is running K-Fold Cross Validation bts.. \n",
    "print(f\" Train score : {train_scores} \\n Test score : {test_scores}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(train_scores, axis=1) \n",
    "test_mean = np.mean(test_scores, axis=1) \n",
    "\n",
    "print(f\" Train mean : {train_mean} \\n Test mean : {test_mean}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(test_mean) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.jointplot(x = np.log(param_rg), y = test_mean)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(test_mean == max(test_mean)))\n",
    "print(param_rg[36]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best case with max value of the set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model_r_best = Ridge(alpha = param_rg[36])  \n",
    "lin_model_r_best.fit(X_train_s, y_train) \n",
    "\n",
    "r2 = r2_score(y_train, lin_model_r_best.predict(X_train_s)) \n",
    "print(f\"r2 train score = {r2}\") \n",
    "\n",
    "r2 = r2_score(y_test, lin_model_r_best.predict(X_test_s)) \n",
    "print(f\"r2 test score = {r2}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
