{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sb \n",
    "\n",
    "# import statsmodels.api as sm \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import r2_score, accuracy_score, confusion_matrix  \n",
    "\n",
    "import nbformat \n",
    "from IPython import get_ipython \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run \"../Data_Preprocessing/data_preprocess.ipynb\" \n",
    "\n",
    "with open(\"../Data_Preprocessing/data_preprocess.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
    "    notebook1 = nbformat.read(f, as_version=4)\n",
    "\n",
    "ipython = get_ipython() \n",
    "\n",
    "for cell in notebook1.cells:\n",
    "    if cell.cell_type == \"code\":\n",
    "        print(cell.source) \n",
    "        if (\"hp_cleaned\" in cell.source or \"hp_d\" in cell.source):\n",
    "            ipython.run_cell(cell.source, silent=True) \n",
    "            # ipython.run_cell_async(cell.source, silent=True) \n",
    "\n",
    "try: \n",
    "    print(\"\\nHouse Price Cleaned Data : \")\n",
    "    print(hp_cleaned.head(), sep='\\n')     # type: ignore \n",
    "except NameError as e:\n",
    "    print(f\"Variable not found: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_cleaned        # type: ignore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_multi = hp_cleaned.loc[:, hp_cleaned.columns != 'Sold']      # type: ignore \n",
    "X_multi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hp_cleaned['Sold']        # type: ignore\n",
    "y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logst_reg = LogisticRegression()  \n",
    "logst_reg = LogisticRegression(max_iter=1000)  \n",
    "logst_reg.fit(X_multi, y)        # X_multi is independent variable and y is dependent  \n",
    "\n",
    "intercept, coef = logst_reg.intercept_ , logst_reg.coef_ \n",
    "print(f\"Linear multiple Regression intercept = {intercept} \\nLinear multiple Regression coefficient = {coef}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train - Test Split :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_multi, y, test_size = 0.2, random_state = 0)    \n",
    "# test_size = 0.2 ~ 20% of the dataset  \n",
    "# random_state : occurance of the sets \n",
    "print(f\" X_train size : {X_train.shape} \\n X_test size : {X_test.shape} \\n y_train size : {y_train.shape} \\n y_test size : {y_test.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logst_model_s = LogisticRegression()  \n",
    "logst_model_s = LogisticRegression(max_iter=1000)  \n",
    "logst_model_s.fit(X_train, y_train) \n",
    "\n",
    "y_train_prd = logst_model_s.predict(X_train) \n",
    "y_test_prd = logst_model_s.predict(X_test) \n",
    "\n",
    "print(f\" r2_score for test set : {r2_score(y_true = y_test, y_pred = y_test_prd)} \") \n",
    "print(f\" r2_score for training set : {r2_score(y_true = y_train, y_pred = y_train_prd)} \") \n",
    "\n",
    "print(f\"Accuracy score for test set : {accuracy_score(y_true = y_test, y_pred = y_test_prd)} \") \n",
    "print(f\"Accuracy score for training set : {accuracy_score(y_true = y_train, y_pred = y_train_prd)} \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mtx_trn = confusion_matrix(y_train, y_train_prd) \n",
    "conf_mtx_trn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mtx_tst = confusion_matrix(y_test, y_test_prd) \n",
    "conf_mtx_tst "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                Linear Discriminant Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LinearDiscriminantAnalysis() \n",
    "lda_model.fit(X_multi, y)  \n",
    "\n",
    "intcp = lda_model.intercept_ \n",
    "coef = lda_model.coef_ \n",
    "\n",
    "print(f\" Linear Discriminant Analysis model intercept = {intcp} \\n Linear Discriminant Analysis model coefficient = {coef} \") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train - Test Split : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lda, X_test_lda, y_train_lda, y_test_lda = train_test_split(X_multi, y, test_size=0.2, random_state=0)   \n",
    "print(f\"LDA :\\n X_train size : {X_train.shape} \\n X_test size : {X_test.shape} \\n y_train size : {y_train.shape} \\n y_test size : {y_test.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_s = LinearDiscriminantAnalysis() \n",
    "lda_model_s.fit(X_train_lda, y_train_lda) \n",
    "\n",
    "y_train_lda_prd = lda_model_s.predict(X_train_lda) \n",
    "y_test_lda_prd = lda_model_s.predict(X_test_lda) \n",
    "\n",
    "print(\"LDA -- \") \n",
    "print(f\" r2_score of training set : {r2_score(y_true=  y_train_lda, y_pred = y_train_lda_prd)} \") \n",
    "print(f\" r2_score of test set : {r2_score(y_true = y_test_lda, y_pred = y_test_lda_prd)} \") \n",
    "\n",
    "print(f\"Accuracy score for training set : {accuracy_score(y_true = y_train_lda, y_pred = y_train_lda_prd)} \")\n",
    "print(f\"Accuracy score for test set : {accuracy_score(y_true = y_test_lda, y_pred = y_test_lda_prd)} \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mtx_lda_trn = confusion_matrix(y_train_lda, y_train_lda_prd) \n",
    "conf_mtx_lda_trn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mtx_lda_tst = confusion_matrix(y_test_lda, y_test_lda_prd) \n",
    "conf_mtx_lda_tst "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
