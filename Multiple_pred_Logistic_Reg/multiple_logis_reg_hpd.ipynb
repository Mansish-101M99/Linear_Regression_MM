{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import seaborn as sb \n",
    "\n",
    "import statsmodels.api as sm \n",
    "import statsmodels.discrete.discrete_model as smdm \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, roc_auc_score   \n",
    "\n",
    "import nbformat \n",
    "from IPython import get_ipython \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run \"../Data_Preprocessing/data_preprocess.ipynb\" \n",
    "\n",
    "with open(\"../Data_Preprocessing/data_preprocess.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
    "    notebook1 = nbformat.read(f, as_version=4)\n",
    "\n",
    "ipython = get_ipython() \n",
    "\n",
    "for cell in notebook1.cells:\n",
    "    if cell.cell_type == \"code\":\n",
    "        print(cell.source) \n",
    "        if (\"hp_cleaned\" in cell.source or \"hp_d\" in cell.source):\n",
    "            ipython.run_cell(cell.source, silent=True) \n",
    "            # ipython.run_cell_async(cell.source, silent=True) \n",
    "\n",
    "try:\n",
    "    print(\"\\nHouse Price Cleaned Data : \")\n",
    "    print(hp_cleaned.head())   # type: ignore \n",
    "    \n",
    "except NameError as e:\n",
    "    print(f\"Variable not found: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_cleaned  # type: ignore "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with Multiple Predictors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hp_cleaned.loc[:, hp_cleaned.columns != 'Sold']        # type: ignore \n",
    "X \n",
    "# df.loc[:, <Allowed_or_not_column(s)>]   ----->>  [:] = all columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hp_cleaned['Sold']       # type: ignore \n",
    "y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_logi_reg = LogisticRegression() \n",
    "cls_logi_reg.fit(X, y)         # X and y are independent variables \n",
    "\n",
    "logm_intercept = cls_logi_reg.intercept_     # beta_0 value \n",
    "logm_coeff = cls_logi_reg.coef_              # beta_n value \n",
    "print(\"Logarithmic classification model intercept = \", logm_intercept, \"\\nLogarithmic classification model coefficient = \", logm_coeff) \n",
    "\n",
    "# print(\"Logarithmic classification model intercept = \", logm_intercept, \"\\nLogarithmic classification model coefficient = \", logm_coeff[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with statsmodels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cons = sm.add_constant(X)     # Here, Beta_0 == 0 \n",
    "X_cons  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit = smdm.Logit(y, X_cons).fit() \n",
    "logit = sm.Logit(y, X_cons).fit() \n",
    "logit.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.jointplot(x=hp_cleaned['price'], y=hp_cleaned['Sold'], data=hp_cleaned, kind='kde')     # type: ignore  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                Confusion Matrix :- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cls_logi_reg.predict(X)          # default boundary condition of predict() : pred_value >= 0.5   \n",
    "y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mtx = confusion_matrix(y, y_pred) \n",
    "conf_mtx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = cls_logi_reg.predict_proba(X)       # boundary condition : X_pred >= 0.5 \n",
    "X_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_3 = int(input(\"Enter a random column from X predictor (0 or 1 only) : \")) \n",
    "\n",
    "y_pred_3 = X_pred[:, col_3] >= 0.3          # Here, boundary condition : pre_value >= 0.3 \n",
    "y_pred_3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mtx = confusion_matrix(y, y_pred_3)  \n",
    "conf_mtx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_7 = int(input(\"Enter a random column from X predictor (0 or 1 only) : \")) \n",
    "\n",
    "y_pred_7 = X_pred[:, col_7] >= 0.7          # Here, boundary condition : pre_value >= 0.7 \n",
    "y_pred_7  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mtx = confusion_matrix(y, y_pred_7)  \n",
    "conf_mtx "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                    Performance Metrics :- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcn_sc = precision_score(y, y_pred)    \n",
    "prcn_sc \n",
    "\n",
    "# Precision score = [ true_positive / (true_positive + false_positive) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcl_sc = recall_score(y, y_pred) \n",
    "rcl_sc \n",
    "\n",
    "# Recall score OR Sensitivity = [ true_positive / (true_positive + false_negative) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_sc = roc_auc_score(y, y_pred) \n",
    "roc_sc \n",
    "\n",
    "# Receiver Operating Characteristic curve : \n",
    "# X-axis = -ve predicted values      ,     Y-axis = +ve predicted values \n",
    "# It should be as far away from the diagonal line for better predicted values yield. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
